\documentclass{article}
\usepackage{fullpage}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{framed}
\usepackage{multicol}
\usepackage{hyperref}

\author{Andrei Soltan\\998556067\\g0soltan@cdf.toronto.edu
\and Jonathan Prindiville\\993177628\\g2prindi@cdf.toronto.edu}
\title{CSC469: Assignment 1}
\date{12 February, 2013}

% Show paragraphs in table of contents
\setcounter{tocdepth}{5}

\lstset{
    mathescape=false,
    basicstyle=\small,
    stringstyle=\ttfamily, % typewriter type for strings
    showstringspaces=false } % no special string spaces

\begin{document}

\maketitle

\tableofcontents

\newpage
\section{Introduction}
Our goal in this assignment is to develop our understanding of performance
measurement and benchmarking as it relates to operating systems -- Linux 3.2
in particular.

Section~\ref{sec:A} contains our exploration of timer interrupts and context
switching between two processes.

Section~\ref{sec:B} will attempt to examine the effect of measurement bias
on several programs, bzip2, lbm and perlbench.

\section{Part A: Performance measurement}
\label{sec:A}
\subsection{Tracking process activity}

\subsubsection{Methodology}
In order to answer the questions that we have, we will be using data collected
from the Pentium TSC register. We'll use the program \lstinline{parta} in order
to collect that data. We first must establish a threshold for the timer
measurements -- above which we will assume that the process has been inactive.
After finding that threshold value, we'll be able to use \lstinline{parta} to
produce a plot showing a process' active and inactive periods over time.

To reduce the number of potentially conflicting processes running on the same
machine, we've written a script (see appendix~\ref{tool:find-empty})
to find empty workstations in the CDF laboratories. Because we hope to extract
measurements in milliseconds, we are choosing to avoid those workstations which
use cpufreq to dynamically set their clock speed (see appendix~\ref{tool:platform}.)

\subsubsection{Results}

\paragraph{Threshold}
In order to find our inactivity threshold we will be using
\lstinline{parta -i -n <num>}. In this mode of operation, we collect
\lstinline{<num>} timer samples in a tight loop and output the difference
between successive samples. Sorting this output and counting intervals of the
same length we will get output like the following, where the left column
represents interval length and the right, number of intervals:
\begin{framed}
    \label{lst:intervals}
    \lstinputlisting[multicols=3]{intervals.log}
\end{framed}

It is clear from the above that the vast majority (\textgreater~99\%) of the
intervals are on the order of one hundred cycles in length. Depending on the
machine, the next smallest interval length tends to be in the 3000-6000 cycle
range. Accordingly, we will use a threshold of 600 cycles in our next
experiment to detect process inactivity.

\paragraph{Process inactivity}
In order to chart process activity we'll need the threshold value which was
established in the previous section and the CPU clock frequency. We strip the
current CPU frequency out of \lstinline{/proc/cpuinfo} with the wrapper script
\lstinline{do-parta.sh}.

With those two items, we can begin to collect data. Similar to when determining
the threshold, we sample the cycle counter in a tight loop. Intervals
of length greater than the threshold value are understood to be times when the
process was pre-empted by the operating system for some reason. Intervals
of length less than the threshold value are interpreted as continuous
activity. Typical output looks like the following (truncated):
\begin{framed}
    \label{lst:inactive}
    \lstinputlisting[lastline=15]{inactive_periods-ms.log}
\end{framed}

We feed this output into gnuplot to obtain the following graph:
\begin{center}
    \begin{figure}[h]
        \label{fig:inactive}
        \caption{Inactive (grey) and active (red) periods of execution}
        \input{inactive_periods-ms}
    \end{figure}
\end{center}

Examination of the data reveals a number of things. The process never seems to 
run for any longer than 4ms without being interrupted. Those are likely to be
the timer interrupts.

If the process is running uncontested, it is able to take advantage of most of
the processor time. Using samples from a number of unoccupied CDF workstations
in b3175, we sum up the inactive periods and express it as a proportion of the
total run time (inactive periods + active periods) and get the following:
\begin{framed}
    \label{lst:proportion}
    \lstinputlisting[multicols=3]{proportion.log}
\end{framed}
Notice the last line indicate that on average (leaving aside the largest and
smallest values) our samples spent less than one percent of their running time
in an inactive state.

For those times that the process has been interrupted by the timer, we see a
very fast handling time. Using samples from an unoccupied CDF machine,
we've selected out the inactive intervals immediately following those active
periods of 3+ milliseconds -- those that were likely
pre-empted by the timer. Below is a listing of those samples and the average
time in milliseconds:
\begin{framed}
    \label{lst:timer}
    \lstinputlisting[multicols=3]{timer.log}
\end{framed}

\subsection{Context switches}

\subsubsection{Methodology}
In order to explore context switching, we were able to use much of the same
code as was used for the process activity experiments in the previous section.
Again, we've taken advantage of empty CDF workstations to run trials.
Specifically those not using adaptive CPU clocks (see the table in 
appendix~\ref{tool:platform}).

When \lstinline{parta} is invoked with the -c flag it will perform the same
timing as described above, accepting
\lstinline{-t <thresh> -n <num> and -f <freq>} arguments. The only
difference is that a child will be forked just prior to the beginning of
data collection. Both parent and child collect their data competing for
CPU time and then the parent waits for the child to exit before printing
(to avoid mixing up the output). The output has the same format as that shown
above for the inactive periods (see~\ref{lst:inactive}),  but there are entries
for both child (first) and parent.

\subsubsection{Results}
The following graph was generated from our output.
\begin{figure}[h]
    \caption{Inactive (grey) and active periods of execution for parent (red)
    and child (blue) processes}
    \input{context_switch-ms}
\end{figure}

We see a clear trading off of processor time, this may not be the case with 
more than two ready processes, but we have been careful to choose unloaded
systems for our trials.

From the figure above and our data, we observe that the timeslices appear to
be around 8ms, or two timer interrupts. On the compute servers greywolf and 
redwolf, the time slices that we were seeing were 16ms.

With the data we've collected we can approximate the cost of a context switch.
Taking the output from \lstinline{parta -c}, we sort by start time and select
out the lines which show inactivity for lengths similar to the timeslice
discussed above\footnote{run\_experiment\_A hardcodes the value of 8 into its
code for extracting this data -- if you are running this on a machine with a
different timeslice, you may not see much of anything in the following listing.
% Hey Andrei, if you're wondering about these guys VVVVVV I am replacing
FYI, this document was put together on @@@DATE@@@ by @@@UNAME@@@.}
% them in run_experiment_A after this file is copied into the log directory
and the line immediately following -- the other process going
into its active state. With some sed and awk massaging, we compute the
difference between the start time of the inactive period and the other
process' active period. A listing of those differences with computed average
(dropping the lowest and highest values) appears below:
\begin{framed}
    \label{lst:switch_time}
    \lstinputlisting[multicols=3]{switch_time.log}
\end{framed}

A surpising result is that the time to handle a context switch is not a great
deal higher than the time we computed for the handling of a timer interrupt.

\newpage
\section{Part B: Measurement bias}
\label{sec:B}

In section we present our investigation of measurement bias. The line of inquiry is similar to the one presented the 2009 ASPOLS paper by Mytkowicz et al.

\subsection{Methodology}
The runtime environment were the machines in lab B23185. Detailed technical specifications about these machines can be found in the \ref{tool:platform} subsection.

In order to measure the differences in performance for each program, they were compiled, with -O2 and -O3 flags, as provided by the given Makefiles. In order to automate the collection of data, and to make the runs as reliable as possible, we developed several bash scrips (e.g partb.sh) that would collect the data for each program individually. This also has the benefit of reducing side effects in the runtime due to cache misses, since the same program is run several times in a row. All programs were run 20 times, both with ASLR disabled and enabled.

In order to collect sufficient data, and to achieve this in a realtively short amount of time, we done repeated runs on different machines. Each batch of 20 iterations of tests for a particular program was run on 5 machines in parallel. This gives us a rough estimate of 100 samples per program in a single ASLR setting. The difference between the machines is negligible for several reasons. First, the machines have identical hardware specifications and operating systems. Second, the benchmarks were run when no user was logged in to any of the machines being used. Lastly, the results are reported in terms of relative speedup. This allows for relatively accurate data, even in the unlikely event of varying performance on identical environments.

\subsection{Results}

Having plotted the relative speedup with O2 vs. O3, in increasing environment sizes with ASLR enabled, we have found that the increasing environment size has a tendency to push the speedup to a higher ratio, when compared with run with smaller environment sizes. However, this tendency is visibly small, with an estimated 2% positive impact of performance.

\begin{figure}[!b]
  \begin{center}
    \includegraphics{partb-plot.eps}
  \end{center}
  \caption{Plot of perlbench time(O2)/time(O3) with varying environment sizes}
\end{figure}

When analysing the impact of ASLR on performance, we have found that programs running with ASLR enabled benefit from a slightly larger speedup than the ones running with ASLR disables. This improvement is on the order of a few percent, rarely reaching 10%. As such, we believe the absence of ASLR does not have a hindering impact on performance. We have observed that in some cases disabling the ASLR had a detrimental impact on the speedup, sometimes decrementing it by 5%-17%. Since, in our measurements, this is the case just for variations of bzip2, we believe this to be due to the specific of the program, and not the absence of ASLR.

\begin{framed}
    \label{lst:inactive}
    \lstinputlisting[lastline=15]{partb.log}
\end{framed}


Future work would include a more careful analysis of the anomalies, making use of statistical tools as well as a larger sample of observations. It would also be important to do more finegrained comparisons between programs based on their inputs and specifications.

\newpage
\appendix
\section{Tools}

\subsection{run\_experiment\_A} \label{tool:run}
This is the main driver for the data collection in section~\ref{sec:A}.
It runs do-parta.sh (see appendix~\ref{tool:parta}) in various permutations
and then massages the output into something suitable for gnuplot or for direct
analysis. We tend to run it on unoccupied lab machines through ssh.

This report is generated after the experiments have completed.


\subsection{parta} \label{tool:parta}
Main information gathering tool used in section~\ref{sec:A}. Collects samples
from the TSC register using the provided tsc.c and tsc.h code.
\begin{framed}
    \label{lst:parta}
    \lstinputlisting{parta.usage}
\end{framed}

\subsection{do-parta.sh} \label{tool:do-parta}
Wrapper for parta (see appendix~\ref{tool:parta}). Main value added is the
ability to select which CPU it will run on, and to extract and pass in the
current CPU clock frequency.
\begin{framed}
    \label{lst:do-parta}
    \lstinputlisting{do-parta.sh.usage}
\end{framed}

\subsection{count-users.sh} \label{tool:count-users.sh}
Used to implement find-empty-wkstn.sh (see appendix~\ref{tool:find-empty}).
Counts the number of unique users currently logged in.

\subsection{find-empty-wkstn.sh} \label{tool:find-empty}
Used to identify CDF workstations that are currently unnocupied. We used free
lab machines to run many of our tests. A little work with \lstinline{ping}
revealed the number of machines in each lab and this script simply loops over
the machines in a specified lab, checking them with \lstinline{count-users.sh}.

For politeness it does a bit of waiting between subsequent checks.
\begin{framed}
    \label{lst:find-empty}
    \lstinputlisting{find-empty-wkstn.sh.usage}
\end{framed}

\subsection{platform-info.sh, gather-platform-info.sh} \label{tool:platform}
Used to get a sense of the hardware available in each of the CDF labs. Of
particular interest was the use of dynamic cpu frequency adjustments --
something that we were trying to avoid in the experiments of
section~\ref{sec:A}.

\begin{center}
    \begin{tabular}{ | c | c | c | c | c | c |}
    \hline
    LAB   & MODEL NO      & Max Frq & N Cores & RAM  & cpufreq governor \\
    \hline 
    b2200 & C2Duo E6550   & 2.33GHz & 2 cores &  2GB & ondemand \\
    b2220 & Pentium G630  & 2.70GHz & 2 cores &  8GB & ondemand \\
    b2240 & Core i5 3570  & 3.40GHz & 4 cores & 20GB & ondemand \\
    b3185 & Pentium E2160 & 1.80GHz & 2 cores &  2GB & ondemand \\
    b3200 & Core i5 650   & 3.20GHz & 4 cores &  1GB & ondemand \\
    \hline
    b2210 & P4            & 3.20GHz & 2 cores &  1GB & none \\
    b3175 & C2 6300       & 1.86GHz & 2 cores &  1GB & none \\
    b3195 & C2 6300       & 1.86GHz & 2 cores &  1GB & none \\
    s2360 & C2 6300       & 1.86GHz & 2 cores &  1GB & none \\
    \hline
\end{tabular}
\end{center}

\subsection{plot-parta.awk}
Transforms output from parta (see~\ref{tool:parta}) inactivity or 
context-switching trials into gnuplot input.

\subsection{active-inactive.awk} \label{tool:active-inactive}
Given output	 from parts (see~\ref{tool:parta}) this computes the amount of time
spent in the active and inactive states as well as the ratio of inactive to
total time.

\subsection{minions.sh} \label{tool:minions}
Given a lab name, a job and the basename for its log files, minions.sh
uses find-empty-wkstn.sh (see~\ref{tool:find-empty}) in order to launch jobs on
all of the empty workstations in that lab.

\subsection{run\_benchmarks\_B} \label{tool:run\_benchmarks\_B}
Runs the benchmarks for partb on multiple hosts. Uses \ref{tool:partb.sh}.

\subsection{partb.sh} \label{tool:partb.sh}
Given a set of tests to run (i.e. bzip2, lbm), runs \ref{tool:partb\_run\_tests.sh} 20 times on the given program, both with and without ASLR. This script also increases the environments size, staring from 1 byte, by 128 bytes, up to 2560 bytes.

\subsection{partb\_run\_tests.sh} \label{tool:partb\_run\_tests.sh}
Run the tests on a given program, based on the given flag. Prints run times for each program, together with infomation about the level of optimisation, the size of the UNIX environment and information whether the ASLR is enabled or not.

\subsection{partb-analyse.sh}
Run analisys of the output of \ref{tool:run\_benchmark\_B}. This tool prints the average runtime improvment for each program, as a fraction of runtime with O2 divided by runtime of O3. The measurements are printed for enviroments with and without ASLR. For processing the output of \ref{tool:run\_benchmarks\_B} this uses \ref{tool:partb-average-speedup.sh} and \label{tool:partb-average-speedup-aslr.sh}.

\subsection{partb-average-speedup.sh} \label{tool:partb-average-speedup.sh}
Parses output of \ref{tool:run\_benchmarks\_B} and returns the average speeup of O2 vs. O3 optiminations for the given program.

\subsection{partb-average-speedup-aslr.sh} \label{tool:partb-average-speedup-aslr.sh}
Parses output of \ref{tool:run\_benchmarks\_B} and returns the average speeup of O2 vs. O3 optiminations for the given program, while also taking into account the different evironments, whether ASLR was enabled or disabled.

\begin{framed}
    \label{lst:minions}
    \lstinputlisting{minions.sh.usage}
\end{framed}

\subsection{usages.sh} \label{tool:usages}
Prints the usage messages of these scripts for inclusion in this report.
\begin{framed}
    \label{lst:usages}
    \lstinputlisting{usages.sh.usage}
\end{framed}


\subsection{awk, grep, sed}
So great!

\end{document}
