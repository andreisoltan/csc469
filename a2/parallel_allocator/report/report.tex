\documentclass{article}
\usepackage{fullpage}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{framed}
\usepackage{multicol}
\usepackage{hyperref}
\usepackage{float}

\author{Andrei Soltan\\998556067\\g0soltan@cdf.toronto.edu
\and Jonathan Prindiville\\993177628\\g2prindi@cdf.toronto.edu}
\title{CSC469: Assignment 2}
\date{15 March, 2013}

% Show paragraphs in table of contents
\setcounter{tocdepth}{5}

\lstset{
    mathescape=false,
    basicstyle=\small,
    stringstyle=\ttfamily, % typewriter type for strings
    showstringspaces=false } % no special string spaces

\begin{document}

\maketitle

\tableofcontents

\newpage
\section{Introduction}

The goal of this assignment is to implement a multithreaded memory allocator.
The challenge is to achieve an implementation that is as fast as a regular 
malloc, and whose performance scales linearly with the increased number of
threads, while at the same time avoiding false sharing and having low 
memory fragmentation. For the approach and the design of the allocator, 
We use as point of reference the Hoard allocator paper \cite{berger00}.
In addition, we have used the description and discussion of the Miser allocator
by Intel \cite{miser-intel}.

We proceed to describe the design of our allocator in section \ref{sec:design}. 
We discuss the decision points in our design and some of the alternatives we 
consided during both implementation and design in section \ref{sec:alternatives}.
Section \ref{sec:performance} discusses the performance details of the allocator
and shows the comparison with other allocators. Finally, section 
\ref{sec:conclusion} presents our conclusions on this multithreaded allocator.

\newpage
\section{Allocator Design}
\label{sec:design}

Our allocators design mimics that of Hoard \cite{berger00} very closely.
Because we were not permitted access to the code there were things which we
had to improvise. Certain requirements of the assignment were influential
on the design as well.

Very broadly, our allocator uses per-CPU heaps with one shared, global heap.
On those heaps are a collection of superblocks. Each superblock is of a
certain size class, meaning that it will only hold allocations of a fixed
(power of two) size. Each heap's collection of superblocks is divided into
separate lists of size classes and then further into a handful of distinct
fullness groups. As superblocks fill up or empty out they are refiled into
the appropriate fullness group.

\subsection{Metadata}
In order to manage our allocator we store a few things globally but try to
minimize this as the assignment requires us to use less than 1k of global
storage. The bulk of the metadata is stored inside the first superblock
of space we receive from mem\_sbrk(). We assign this first superblock an
arbitrary (small) size class in the hopes that the space will be used by
calls to mm\_malloc().

Because we know that this first allocation is based at dseg\_lo we can use
some pointer arithmetic to later find our heap structures. We simply offset
from desg\_lo by the size of the superblock header and treat that address as
a heap structure pointer. Using array notation, we can access the global
heap (at index 0) and the per-CPU heaps (at indices [1, number of CPUs]).

\subsubsection{Globals}
We hold an array, size\_classes, containing at size\_classes[i] the size
in bytes of the i\textsuperscript{th} size class. Size class 0 is used to
store empty superblocks which we treat as not having any size class.

We store the system's page size and our superblock size as global variables
after computing them during mm\_init().

Because calls to mem\_sbrk() must be serialized (reference assignment?), we
store a global lock, sbrk\_lock.

For our list of large allocations, we store the pointer to the head of the
list and a lock for it in the global space.

For debugging builds we chose to use pthread\_mutexes of type
PTHREAD\_MUTEX\_ERRORCHECK, so we have a global pthread\_mutexattr\_t in which
to store the type. Only enabled in such builds, we also have counters for
number of mallocs and frees.

\subsubsection{Heaps}
As mentioned above, we store our heap structures in the first superblock
that is requested from the system. Each heap structure contains the following:
\begin{description}
    \item[lock] a pthread\_mutex\_t
    \item[usage] the number of bytes currently stored in the heap
    \item[allocated] the current capacity in bytes of this heap
        (equal to the number of superblocks on the heap * superblock size)
    \item[sizes] an array containing, for each size class, pointers to
        its fullness groups: full, fullish, and emptyish.
\end{description}

\subsubsection{Superblocks}
A superblock structure is written at the header of each allocated superblock.
That header contains the following information:
\begin{description}
    \item[lock] a pthread\_mutex\_t
    \item[usage] the number of bytes currently stored in this superblock
    \item[heap] the heap number this superblock is currently associated with
    \item[size\_class] index into global size\_classes, describing the block
        size held in this superblock
    \item[prev] linked-list pointer for navigating within fullness group
    \item[next] linked-list pointer for navigating within fullness group
    \item[group] pointer to pointer to head of current fullness group
    \item[free] head of freelist linked-list (singly linked)
\end{description}

The freelist is stored in the free space of the superblock. The memory
location of a freelist node is taken to mark the head of an unallocated block.

\subsection {Behaviour}
As discussed above, our first order of business is to obtain a superblock-sized
piece of memory from the system. We write some bookkeeping structures onto it,
give it a size class which will likely be used by the calling programs and then
create a freelist in the space between our header and the end of the
superblock. This initial superblock is then put onto the global heap before we
return from mm\_init().

\subsubsection{Allocation}
Normal allocations follow much the same pattern as in Hoard. We find which of
our power of two size classes the request will fit into. If none are large 
enough, we'll take a different approach, detailed below.

Upon establishing the size class, we begin to search for a superblock with
free space in the current CPU's heap -- first in the size class, and then in the
empty, unclassified superblocks. If nothing suitable is found there, we search
the global heap for something of the correct size class and then for an empty
superblock. If we still have not found anything we'll request another
superblock's worth of memory from the system.

In any case, we take that superblock and insert it into our current CPU's heap.
This insertion puts the superblock at the head of the appropriate fullness
group's list. Head insertion is beneficial because we can do it in constant
time and also because recently accessed superblocks will remain at the front
of our lists, and hopefully stay in cache. We mimic this behaviour from Hoard.

\paragraph{Fullness groups}
Superblocks are segregated into fullness groups based on the fraction
(usage / sb\_size) as follows:
\begin{description}
    \item[full] fullness = 1.0
    \item[fullish] fullness \in (1.0, SB\_EMPTYFRAC)
    \item[emptyish] fullness \in [SB\_EMPTYFRAC, 0]
\end{description}

When searching non-empty superblocks, we prefer to allocate from a fullish
superblock. The intention is that those superblocks are more likely to be 
cache- and/or memory-resident.

\paragraph{Large allocation}
How do we handle rhe really large allocations?

\subsubsection{Freeing}
When we recieve a free request we first must determine of it is one of the
large allocations, or if it is a normal superblock-stored allocation. We
search the list of large allocations -- this is not a very fast operation,
we've chosen this method for simplicity because the benchmarks we are testing
against do not do many large allocations -- if it is not found there, we
assume that it is on a superblock. Some pointer arithmetic will find us the 
superblock's header and then we can update the heap and superblock's
statistics. We re-insert the superblock in question at the head of its
fullness group (hoping to keep it cache- and/or memory-resident) and then
check to see if we should release a superblock up to the global heap.

\subsubsection{Superblock release}
As in Hoard, we determine whether or not to move a superblock from the CPU's
heap up to the global heap based on the usage/allocated statistics and
two parameters: 
\begin{description}
    \item[SB\_RELTHRESHOLD] Free space on heap (measured in superblocks)
        before we consider releasing a superblock
    \item[SB\_EMPTYFRAC] Fullness percentage of heap below which we will
        release a superblock.
\end{description}

Once we determine we must release a superblock it is chosen by the following
logic. We prefer to release from size class 0, the empty superblocks. If none
are available there, we look at each size class' emptyish list taking the
first one that we encounter.

Was there something we did to boost performance? (mention memory usage, 
processing, internal and external fragmentation (with no numbers?))

What other questions do we want to answer or design decisions that we think
are worth mentioning?

\newpage
\section{Design Alternatives}
\label{sec:alternatives}

Insert smart text about other features we considered for our allocator...

Was there something that would work better but is too hard to develop?

Was there something that was easier to develop but would give slightly slower
performance?

Was there something we tried, but found that it wouldn't work well (or took too 
much time/effort), and decided in favor of a simpler solution?

Was there something we did, avoided or fixed to have good performance?

Did we decided in favor or against something regarding fragmentation?

Should this a subsection of the Design section above?

\newpage
\section{Performance Analysis}
\label{sec:performance}

Insert smart text about how well our allocator performs...

\textbf{MUST HAVE} or we lose marks for not mentioning (from grading rubric)
\begin{itemize}
	\item Sequential Speed
	\item Scalability
	\item False Sharing Avoidance
	\item Fragmentation
\end{itemize}

Describe the experimental setup. (Subsection?)

Describe the performance measurements. \textbf{Must} have plenty of numbers 
(i.e. not "very few" according to rubric). (Subsection?)

Describe the memory usage, utilization, overhead, internal and external 
fragmentation. Pay significant attention to \textbf{fragmentation} and 
\textbf{usage}. Look at Hoard paper, performance section. 

\newpage
\section{Conclusion}
\label{sec:conclusion}

Insert smart text about how we did awesome... This might take work. :)

\newpage

% Declare the bibligraphy to use one-digit indexes.
\begin{thebibliography}{9}
	
	\bibitem{berger00}
		Berger, Emery D., et al.
		"Hoard: A scalable memory allocator for multithreaded applications."
		\textit{ACM SIGPLAN Notices} 35.11 
		(2000): 
		117-128.
	\bibitem{miser-intel}
		Lewin, Stephen.
		"Miser - A Dynamically Loadable Memory Allocator for Multi-Threaded Applications."
		\textit{Intel Developer Zone.}
		Intel, 
		n.d. Web. 10 Mar. 2013.

\end{thebibliography}

\end{document}
